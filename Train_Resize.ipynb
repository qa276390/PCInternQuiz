{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tsai/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14510\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config = config)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import shutil\n",
    "tStart = time.time()\n",
    "print(os.getpid())\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model2(config):\n",
    "    filt_size = (3, 3)\n",
    "    model2 = Sequential()\n",
    "    model2.add(Convolution2D(32, filt_size, input_shape=config.dim, activation='relu', padding='same'))\n",
    "    print(config.dim)\n",
    "    model2.add(Convolution2D(32, filt_size, activation='relu', padding='same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(MaxPooling2D((2,2)))\n",
    "    model2.add(Dropout(0.5))\n",
    "    \n",
    "    model2.add(Convolution2D(64, filt_size, activation='relu', padding='same'))\n",
    "    model2.add(Convolution2D(64, filt_size, activation='relu', padding='same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(MaxPooling2D((2,2)))\n",
    "    model2.add(Dropout(0.5))\n",
    "    \n",
    "    model2.add(Convolution2D(128, filt_size, activation='relu', padding='same'))\n",
    "    model2.add(Convolution2D(128, filt_size, activation='relu', padding='same'))\n",
    "    #model2.add(Convolution2D(128, filt_size, activation='relu', padding='same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(MaxPooling2D((2,2)))\n",
    "    model2.add(Dropout(0.5))\n",
    "    \n",
    "    model2.add(Convolution2D(256, filt_size, activation='relu', padding='same'))\n",
    "    #model2.add(Convolution2D(256, filt_size, activation='relu', padding='same'))\n",
    "    #model2.add(Convolution2D(256, filt_size, activation='relu', padding='same'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(MaxPooling2D((2,2)))\n",
    "    model2.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128, activation='relu'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(Dense(96, activation='relu'))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(Dense(1))\n",
    "    model2.add(Activation('linear'))\n",
    "    \n",
    "    opt = optimizers.Adam(config.learning_rate)\n",
    "\n",
    "    model2.compile(optimizer=opt, loss=keras.losses.mean_squared_error, metrics=['mae'])\n",
    "    return model2\n",
    "\n",
    "def _shuffle(X, Y):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "\n",
    "    return (X[randomize], Y[randomize])\n",
    "\n",
    "def __shuffle(X):\n",
    "    randomize = np.arange(len(X))\n",
    "    np.random.shuffle(randomize)\n",
    "\n",
    "    return X[randomize]\n",
    "\n",
    "def split_valid_set(X_all, Y_all, percentage):\n",
    "    all_data_size = len(X_all)\n",
    "    valid_data_size = int(math.floor(all_data_size * percentage))\n",
    "\n",
    "    #X_all, Y_all = _shuffle(X_all, Y_all)\n",
    "\n",
    "    X_train, Y_train = X_all[0:valid_data_size], Y_all[0:valid_data_size]\n",
    "    X_valid, Y_valid = X_all[valid_data_size:], Y_all[valid_data_size:]\n",
    "\n",
    "    return X_train, Y_train, X_valid, Y_valid\n",
    "\n",
    "\n",
    "def split_valid_index(total_len, percentage):\n",
    "    all_data_size = total_len\n",
    "    valid_data_size = int(math.floor(all_data_size * percentage))\n",
    "\n",
    "    x = np.arange(total_len)\n",
    "    x_all = __shuffle(x)\n",
    "\n",
    "    return x_all[0:valid_data_size], x_all[valid_data_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parse_Data():\n",
    "    path = './data/feat.csv'\n",
    "    df = pd.read_pickle(path)\n",
    "    Y_train = df['corr']\n",
    "    #data = df.drop('corr', axis =1 )\n",
    "    data = df.feat\n",
    "    print(np.shape(data))\n",
    "    X_train = data\n",
    "\n",
    "\n",
    "    print(np.shape(X_train))\n",
    "    print(np.shape(Y_train))\n",
    "    \n",
    "    return X_train, Y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000,)\n",
      "(150000,)\n",
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "X, Y = Parse_Data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 75, 75, 3)\n"
     ]
    }
   ],
   "source": [
    "newX = np.zeros((np.shape(X)[0], np.shape(X[0])[0],  np.shape(X[0])[1], 3))\n",
    "print(np.shape(newX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(np.shape(X)[0]):\n",
    "    newX[i, :, :, :] = X[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#X_train = newX\n",
    "#y_train = Y\n",
    "X_train, y_train, X_test, y_test = split_valid_set(newX, Y, 0.33)\n",
    "# mem error if shuffle\n",
    "#X_train, X_test, y_train, y_test = train_test_split(newX, Y, test_size=0.33, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49500,)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import Sequence, to_categorical\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(object):\n",
    "    def __init__(self, learning_rate=0.001, max_epochs=50, dim = (75, 75, 3), n_folds = 5):\n",
    "    \n",
    "       \n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_epochs = max_epochs\n",
    "        self.dim = dim\n",
    "        self.n_folds = n_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(learning_rate=0.001,  dim = (75, 75, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers\n",
    "from keras.layers import Dense, Activation, Flatten, Conv2D, MaxPooling2D,BatchNormalization, Dropout\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras.callbacks import (EarlyStopping, LearningRateScheduler,\n",
    "                             ModelCheckpoint, TensorBoard, ReduceLROnPlateau)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = \"resize_img_only\"\n",
    "if not os.path.exists(PREDICTION_FOLDER):\n",
    "    os.mkdir(PREDICTION_FOLDER)\n",
    "if os.path.exists('logs/' + PREDICTION_FOLDER):\n",
    "    shutil.rmtree('logs/' + PREDICTION_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 75, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 9, 9, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 96)                12384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 96)                384       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,121,889\n",
      "Trainable params: 1,120,481\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n",
      "Train on 37125 samples, validate on 12375 samples\n",
      "Epoch 1/100\n",
      "37125/37125 [==============================] - 38s 1ms/step - loss: 1.6862 - mean_absolute_error: 0.9767 - val_loss: 4.4673 - val_mean_absolute_error: 1.8046\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.46733, saving model to resize_img_onlybest.h5\n",
      "Epoch 2/100\n",
      "37125/37125 [==============================] - 30s 819us/step - loss: 0.3677 - mean_absolute_error: 0.4622 - val_loss: 0.8930 - val_mean_absolute_error: 0.7701\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.46733 to 0.89302, saving model to resize_img_onlybest.h5\n",
      "Epoch 3/100\n",
      "37125/37125 [==============================] - 30s 818us/step - loss: 0.1006 - mean_absolute_error: 0.2437 - val_loss: 0.3002 - val_mean_absolute_error: 0.4312\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.89302 to 0.30023, saving model to resize_img_onlybest.h5\n",
      "Epoch 4/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0431 - mean_absolute_error: 0.1630 - val_loss: 0.3144 - val_mean_absolute_error: 0.4263\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.30023\n",
      "Epoch 5/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0302 - mean_absolute_error: 0.1378 - val_loss: 0.2828 - val_mean_absolute_error: 0.4126\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.30023 to 0.28275, saving model to resize_img_onlybest.h5\n",
      "Epoch 6/100\n",
      "37125/37125 [==============================] - 30s 818us/step - loss: 0.0253 - mean_absolute_error: 0.1261 - val_loss: 0.1651 - val_mean_absolute_error: 0.3306\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.28275 to 0.16511, saving model to resize_img_onlybest.h5\n",
      "Epoch 7/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0229 - mean_absolute_error: 0.1198 - val_loss: 0.1728 - val_mean_absolute_error: 0.3318\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.16511\n",
      "Epoch 8/100\n",
      "37125/37125 [==============================] - 30s 819us/step - loss: 0.0209 - mean_absolute_error: 0.1144 - val_loss: 0.1262 - val_mean_absolute_error: 0.2901\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.16511 to 0.12621, saving model to resize_img_onlybest.h5\n",
      "Epoch 9/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0195 - mean_absolute_error: 0.1104 - val_loss: 0.1094 - val_mean_absolute_error: 0.2653\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.12621 to 0.10939, saving model to resize_img_onlybest.h5\n",
      "Epoch 10/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0182 - mean_absolute_error: 0.1063 - val_loss: 0.0931 - val_mean_absolute_error: 0.2464\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.10939 to 0.09309, saving model to resize_img_onlybest.h5\n",
      "Epoch 11/100\n",
      "37125/37125 [==============================] - 31s 822us/step - loss: 0.0169 - mean_absolute_error: 0.1026 - val_loss: 0.0829 - val_mean_absolute_error: 0.2363\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.09309 to 0.08286, saving model to resize_img_onlybest.h5\n",
      "Epoch 12/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0162 - mean_absolute_error: 0.0998 - val_loss: 0.0701 - val_mean_absolute_error: 0.2194\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.08286 to 0.07009, saving model to resize_img_onlybest.h5\n",
      "Epoch 13/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0155 - mean_absolute_error: 0.0977 - val_loss: 0.0649 - val_mean_absolute_error: 0.2017\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.07009 to 0.06489, saving model to resize_img_onlybest.h5\n",
      "Epoch 14/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0148 - mean_absolute_error: 0.0953 - val_loss: 0.0548 - val_mean_absolute_error: 0.1949\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06489 to 0.05480, saving model to resize_img_onlybest.h5\n",
      "Epoch 15/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0143 - mean_absolute_error: 0.0939 - val_loss: 0.0465 - val_mean_absolute_error: 0.1764\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.05480 to 0.04648, saving model to resize_img_onlybest.h5\n",
      "Epoch 16/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0140 - mean_absolute_error: 0.0926 - val_loss: 0.0368 - val_mean_absolute_error: 0.1561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00016: val_loss improved from 0.04648 to 0.03677, saving model to resize_img_onlybest.h5\n",
      "Epoch 17/100\n",
      "37125/37125 [==============================] - 30s 819us/step - loss: 0.0135 - mean_absolute_error: 0.0908 - val_loss: 0.0442 - val_mean_absolute_error: 0.1750\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.03677\n",
      "Epoch 18/100\n",
      "37125/37125 [==============================] - 30s 819us/step - loss: 0.0135 - mean_absolute_error: 0.0902 - val_loss: 0.0330 - val_mean_absolute_error: 0.1488\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03677 to 0.03300, saving model to resize_img_onlybest.h5\n",
      "Epoch 19/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0135 - mean_absolute_error: 0.0905 - val_loss: 0.0272 - val_mean_absolute_error: 0.1348\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.03300 to 0.02722, saving model to resize_img_onlybest.h5\n",
      "Epoch 20/100\n",
      "37125/37125 [==============================] - 31s 822us/step - loss: 0.0133 - mean_absolute_error: 0.0896 - val_loss: 0.0267 - val_mean_absolute_error: 0.1339\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02722 to 0.02671, saving model to resize_img_onlybest.h5\n",
      "Epoch 21/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0122 - mean_absolute_error: 0.0862 - val_loss: 0.0369 - val_mean_absolute_error: 0.1575\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.02671\n",
      "Epoch 22/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0119 - mean_absolute_error: 0.0852 - val_loss: 0.0351 - val_mean_absolute_error: 0.1555\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.02671\n",
      "Epoch 23/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0124 - mean_absolute_error: 0.0867 - val_loss: 0.0163 - val_mean_absolute_error: 0.1014\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02671 to 0.01631, saving model to resize_img_onlybest.h5\n",
      "Epoch 24/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0115 - mean_absolute_error: 0.0834 - val_loss: 0.0237 - val_mean_absolute_error: 0.1253\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01631\n",
      "Epoch 25/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0115 - mean_absolute_error: 0.0836 - val_loss: 0.0336 - val_mean_absolute_error: 0.1515\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01631\n",
      "Epoch 26/100\n",
      "37125/37125 [==============================] - 31s 822us/step - loss: 0.0111 - mean_absolute_error: 0.0820 - val_loss: 0.0198 - val_mean_absolute_error: 0.1128\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01631\n",
      "Epoch 27/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0111 - mean_absolute_error: 0.0819 - val_loss: 0.0263 - val_mean_absolute_error: 0.1317\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01631\n",
      "Epoch 28/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0109 - mean_absolute_error: 0.0812 - val_loss: 0.0217 - val_mean_absolute_error: 0.1191\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01631\n",
      "Epoch 29/100\n",
      "37125/37125 [==============================] - 30s 822us/step - loss: 0.0105 - mean_absolute_error: 0.0798 - val_loss: 0.0312 - val_mean_absolute_error: 0.1448\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01631\n",
      "Epoch 30/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0114 - mean_absolute_error: 0.0826 - val_loss: 0.0125 - val_mean_absolute_error: 0.0887\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.01631 to 0.01250, saving model to resize_img_onlybest.h5\n",
      "Epoch 31/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0111 - mean_absolute_error: 0.0815 - val_loss: 0.0270 - val_mean_absolute_error: 0.1339\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.01250\n",
      "Epoch 32/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0113 - mean_absolute_error: 0.0821 - val_loss: 0.0233 - val_mean_absolute_error: 0.1249\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.01250\n",
      "Epoch 33/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0103 - mean_absolute_error: 0.0787 - val_loss: 0.0282 - val_mean_absolute_error: 0.1384\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.01250\n",
      "Epoch 34/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0095 - mean_absolute_error: 0.0760 - val_loss: 0.0335 - val_mean_absolute_error: 0.1516\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.01250\n",
      "Epoch 35/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0100 - mean_absolute_error: 0.0773 - val_loss: 0.0255 - val_mean_absolute_error: 0.1317\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.01250\n",
      "Epoch 36/100\n",
      "37125/37125 [==============================] - 30s 821us/step - loss: 0.0109 - mean_absolute_error: 0.0805 - val_loss: 0.0258 - val_mean_absolute_error: 0.1315\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.01250\n",
      "Epoch 37/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0095 - mean_absolute_error: 0.0757 - val_loss: 0.0273 - val_mean_absolute_error: 0.1352\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.01250\n",
      "Epoch 38/100\n",
      "37125/37125 [==============================] - 30s 822us/step - loss: 0.0095 - mean_absolute_error: 0.0755 - val_loss: 0.0435 - val_mean_absolute_error: 0.1731\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.01250\n",
      "Epoch 39/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0101 - mean_absolute_error: 0.0775 - val_loss: 0.0299 - val_mean_absolute_error: 0.1424\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.01250\n",
      "Epoch 40/100\n",
      "37125/37125 [==============================] - 30s 820us/step - loss: 0.0094 - mean_absolute_error: 0.0748 - val_loss: 0.0333 - val_mean_absolute_error: 0.1489\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.01250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "checkpoint = ModelCheckpoint(PREDICTION_FOLDER + '/best.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=10)\n",
    "tb = TensorBoard(log_dir='./logs/' + PREDICTION_FOLDER, write_graph=True)\n",
    "\n",
    "callbacks_list = [checkpoint, early, tb]\n",
    "\n",
    "model = Model2(config)\n",
    "model.summary()\n",
    "\n",
    "history =  model.fit(X_train, y_train, batch_size = 256, validation_split = 0.25, epochs = 100, verbose = 1, callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 75, 75, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 75, 75, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 37, 37, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 37, 37, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 37, 37, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 37, 37, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 18, 18, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 18, 18, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 18, 18, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 9, 9, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 9, 9, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               524416    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 96)                12384     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 96)                384       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 96)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 97        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,121,889\n",
      "Trainable params: 1,120,481\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100500/100500 [==============================] - 40s 397us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_weights(PREDICTION_FOLDER + '/best.h5')\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.legend(['training', 'validation'], loc = 'upper left')\n",
    "plt.show()\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  0.012382846880611496\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: ', results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
